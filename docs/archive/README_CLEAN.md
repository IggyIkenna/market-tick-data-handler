# Market Tick Data Handler

A streamlined repository for downloading, processing, and managing market tick data from Tardis.dev with proper GCS partitioning.

## ğŸ¯ Core Functions

This repository provides exactly **5 core functions**:

### 1. **Instrument Definition Generation**
Download and process Tardis symbol data from `https://api.tardis.dev/v1/exchanges/{exchange}` into instrument definitions/keys and upload to GCS with proper partitioning.

### 2. **Download Target Definition** 
Pull GCS instrument definition data and use it to define which instruments we want to download Tardis data for using Tardis exchange and symbol.

### 3. **Data Download & Upload**
Download Tardis CSV.gz data locally then push to GCS following the `UNIVERSAL_PARTITIONING_STRATEGY.md` format.

### 4. **Missing Data Validation**
Create missing data check comparing instrument definitions vs availability of data in GCS for those instruments over a query timeframe.

### 5. **Orchestration**
Orchestrate Tardis data download in local deployment or cloud VM deployment with sharding by date.

## ğŸ“ Repository Structure

```
market-tick-data-handler/
â”œâ”€â”€ src/                           # Core modules
â”‚   â”œâ”€â”€ instrument_processor/      # Function 1: Instrument definitions
â”‚   â”‚   â”œâ”€â”€ canonical_key_generator.py
â”‚   â”‚   â””â”€â”€ gcs_uploader.py
â”‚   â”œâ”€â”€ data_downloader/           # Functions 2 & 3: Data download
â”‚   â”‚   â”œâ”€â”€ instrument_reader.py
â”‚   â”‚   â”œâ”€â”€ download_orchestrator.py
â”‚   â”‚   â””â”€â”€ tardis_connector.py
â”‚   â”œâ”€â”€ data_validator/            # Function 4: Data validation
â”‚   â”‚   â””â”€â”€ data_validator.py
â”‚   â””â”€â”€ orchestrator/              # Function 5: Orchestration
â”‚       â””â”€â”€ market_data_orchestrator.py
â”œâ”€â”€ deploy                       # Utility scripts
â”œâ”€â”€ deploy/                        # Deployment configurations
â”œâ”€â”€ docs/                          # Documentation
â”œâ”€â”€ archive/                       # Deprecated files
â”œâ”€â”€ main.py                        # Main entry point
â”œâ”€â”€ config.py                      # Configuration
â””â”€â”€ requirements.txt               # Dependencies
```

## ğŸš€ Quick Start

### Installation

```bash
pip install -r requirements.txt
```

### Configuration

1. Copy `env.example` to `.env`
2. Add your Tardis API key
3. Configure GCS bucket settings

### Usage

```bash
# Run the complete pipeline
python main.py

# Or run individual functions programmatically
from src.orchestrator import MarketDataOrchestrator

orchestrator = MarketDataOrchestrator("your-gcs-bucket", "your-api-key")
results = orchestrator.run_local_deployment()
```

## ğŸ“Š Data Partitioning - BigQuery Optimized (Max 4 Levels)

All data follows the `UNIVERSAL_PARTITIONING_STRATEGY.md` with **BigQuery clustering optimization** and **maximum 4 levels of depth**:

```
gs://your-bucket/
â”œâ”€â”€ instrument_availability/        # Instrument definitions (max 4 levels)
â”‚   â”œâ”€â”€ by_date/day-2024-01-15/instruments.parquet
â”‚   â”œâ”€â”€ by_venue/day-2024-01-15/instruments.parquet
â”‚   â”œâ”€â”€ by_type/day-2024-01-15/instruments.parquet
â”‚   â””â”€â”€ instruments_20240115.parquet
â””â”€â”€ raw_tick_data/                 # Market data (max 4 levels)
    â”œâ”€â”€ by_date/data_type-trades/venue-deribit/deribit:Perp:BTC-USDT.parquet
    â”œâ”€â”€ by_venue/data_type-trades/venue-deribit/deribit:Perp:BTC-USDT.parquet
    â””â”€â”€ by_type/data_type-trades/type-perp/deribit:Perp:BTC-USDT.parquet
```

**ğŸš€ BigQuery Clustering Benefits:**
- **Max 4 levels**: partition_type, data_type/day, venue/type, instrument_key
- **No over-partitioning**: Optimal depth for GCS and BigQuery
- **Fast queries**: One file per directory enables lightning-fast GCS queries
- **3-column clustering**: Respects BigQuery's clustering limit + day partition

## ğŸ”§ Core Components

### Instrument Processor
- `CanonicalInstrumentKeyGenerator`: Generates standardized instrument keys
- `InstrumentGCSUploader`: Uploads definitions with proper partitioning

### Data Downloader  
- `InstrumentReader`: Reads instrument definitions from GCS
- `DownloadOrchestrator`: Downloads Tardis data and uploads to GCS
- `TardisConnector`: Handles Tardis API interactions

### Data Validator
- `DataValidator`: Compares expected vs actual data availability

### Orchestrator
- `MarketDataOrchestrator`: Main pipeline coordinator

## ğŸ“ˆ Performance

- **Instrument Generation**: ~293K Deribit symbols processed in seconds
- **Data Download**: Optimized with single API call per exchange
- **GCS Upload**: BigQuery-optimized partitioning with max 4 levels for lightning-fast queries
- **Validation**: Efficient missing data detection
- **BigQuery Ready**: Respects 3-column clustering limit + day partition for maximum performance

## ğŸ—ï¸ Deployment

### Local Deployment
```bash
python main.py
```

### Cloud VM Deployment
```bash
# Use existing VM orchestration scripts
./deploy/orchestration/deploy_vms.sh
```

## ğŸ“š Documentation

- `docs/UNIVERSAL_PARTITIONING_STRATEGY.md`: Data partitioning strategy
- `docs/INSTRUMENT_KEY.md`: Instrument key specification
- `archive/`: Deprecated scripts and documentation

## ğŸ§¹ Cleanup

Deprecated scripts have been moved to `archive/deprecated_deploy`:
- Debug scripts
- Test scripts  
- Optimization demos
- Working prototypes

The repository now focuses solely on the 5 core functions with a clean, modular architecture.
