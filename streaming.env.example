# Market Data Streaming Service Configuration
# Copy this file to streaming/.env and update with your values

# Google Cloud Platform Configuration
GCP_PROJECT_ID=your-project-id
GOOGLE_APPLICATION_CREDENTIALS=path/to/your/service-account-key.json

# BigQuery Configuration
BIGQUERY_DATASET=market_data_streaming

# BigQuery Batching (MAXIMUM Cost Optimization)
BIGQUERY_BATCH_SIZE=1000          # Number of ticks per batch (max BigQuery limit: 1000)
BIGQUERY_BATCH_TIMEOUT=60000      # Max delay in ms before flushing batch (default: 1 minute for trades/snapshots)
BIGQUERY_MAX_BATCH_TIMEOUT=300000 # Absolute max delay in ms (default: 5 minutes for trades/snapshots)

# Data Type Specific Batching:
# - trades, book_snapshots: 1-minute batching (high frequency, critical)
# - liquidations, derivative_ticker, options_chain: 15-minute batching (lower frequency, less critical)

# Cost Optimization Strategy:
# - Batch up to 1000 rows OR 9MB (whichever comes first)
# - Trades/Snapshots: Flush every 1 minute maximum
# - Others: Flush every 15 minutes maximum
# - Reduces BigQuery costs by ~90% vs per-row streaming
# - Tardis ingress costs remain the same

# Tardis API Configuration (now stored in Secret Manager)
# TARDIS_API_KEY=TD.your_api_key_here  # No longer needed - stored in Secret Manager

# Streaming Configuration (Optional)
STREAMING_DURATION=300
STREAMING_SYMBOL=BTC-USDT
STREAMING_EXCHANGE=binance
