#!/usr/bin/env python3
"""
Demo: Unified Streaming Architecture
Shows live candle processing with HFT features and BigQuery streaming
"""

import asyncio
import sys
import os
import logging
from datetime import datetime, timezone, timedelta
from typing import Dict, Any
import json

# Add the streaming service to path
sys.path.insert(0, 'market_data_tick_handler/streaming_service')

# Import components directly
from tick_processor.tick_handler import TickHandler, TickData
from tick_processor.data_type_router import DataTypeRouter
from candle_processor.live_candle_processor import LiveCandleProcessor, LiveProcessingConfig
from hft_features.feature_calculator import HFTFeatureCalculator
from bigquery_client.streaming_client import BigQueryStreamingClient, StreamingConfig
from modes.serve_mode import ServeMode, ServeConfig
from modes.persist_mode import PersistMode, PersistConfig

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class UnifiedStreamingDemo:
    """Demo of the unified streaming architecture"""
    
    def __init__(self):
        self.symbol = "BTC-USDT"
        self.exchange = "binance"
        
        # Initialize components
        self.tick_handler = TickHandler()
        self.candle_processor = LiveCandleProcessor(
            self.symbol,
            LiveProcessingConfig(
                timeframes=['15s', '1m'],
                enable_hft_features=True
            )
        )
        
        # Serve mode (in-memory for demo)
        self.serve_mode = ServeMode(ServeConfig(transport="inmemory"))
        
        # Mock persist mode (no real BigQuery for demo)
        self.persist_mode = None
        
        # Statistics
        self.stats = {
            'ticks_processed': 0,
            'candles_completed': 0,
            'hft_features_computed': 0,
            'start_time': datetime.now(timezone.utc)
        }
    
    async def generate_mock_ticks(self, duration_seconds=60):
        """Generate realistic mock tick data"""
        logger.info(f"üé≠ Generating mock ticks for {duration_seconds} seconds...")
        
        base_price = 67000.0
        base_time = datetime.now(timezone.utc)
        
        tick_count = 0
        
        for i in range(duration_seconds * 10):  # 10 ticks per second
            # Simulate realistic price movement
            price_change = (i % 20 - 10) * 0.5  # Oscillating price
            current_price = base_price + price_change
            
            # Simulate varying trade sizes
            amount = 0.001 + (i % 5) * 0.02
            
            # Create tick
            tick_time = base_time + timedelta(milliseconds=i * 100)
            
            tick_data = {
                'symbol': self.symbol,
                'exchange': self.exchange,
                'timestamp': tick_time,
                'data_type': 'trades',
                'price': current_price,
                'amount': amount,
                'side': 'buy' if i % 2 == 0 else 'sell',
                'trade_id': f'mock_{i}'
            }
            
            yield tick_data
            tick_count += 1
            
            # Small delay to simulate realistic timing
            await asyncio.sleep(0.01)  # 10ms between ticks
    
    async def process_tick_stream(self):
        """Process the mock tick stream through the unified architecture"""
        logger.info("üöÄ Starting unified streaming demo...")
        logger.info("=" * 60)
        
        completed_candles = []
        
        # Process ticks through the unified pipeline
        async for raw_tick in self.generate_mock_ticks(duration_seconds=90):
            # Step 1: Process tick through tick handler
            processed_tick = await self.tick_handler.process_tick(raw_tick)
            if processed_tick:
                self.stats['ticks_processed'] += 1
            
            # Step 2: Process through candle processor (unified with historical)
            candles = await self.candle_processor.process_tick(raw_tick)
            
            # Step 3: Handle completed candles
            for candle in candles:
                self.stats['candles_completed'] += 1
                completed_candles.append(candle)
                
                # Show candle with HFT features
                await self._display_candle_with_features(candle)
                
                # Step 4: Serve mode (publish to downstream services)
                hft_features = getattr(candle, 'hft_features', None)
                if hft_features:
                    self.stats['hft_features_computed'] += 1
                    await self.serve_mode.serve_candle_with_features(candle, hft_features)
                
                # Step 5: Mock BigQuery streaming (would persist in real deployment)
                await self._mock_bigquery_streaming(candle, hft_features)
        
        # Final statistics
        await self._show_final_stats(completed_candles)
    
    async def _display_candle_with_features(self, candle):
        """Display completed candle with HFT features"""
        timestamp_str = candle.timestamp_in.strftime('%H:%M:%S')
        
        # Calculate processing latency
        processing_latency = 0
        if candle.timestamp_out:
            processing_latency = (candle.timestamp_out - candle.timestamp_in).total_seconds() * 1000
        
        print(f"\nüïØÔ∏è  COMPLETED {candle.timeframe} CANDLE - {candle.symbol}")
        print(f"   Time: {timestamp_str} UTC")
        print(f"   OHLCV: O=${candle.open:.2f} H=${candle.high:.2f} L=${candle.low:.2f} C=${candle.close:.2f}")
        print(f"   Volume: {candle.volume:.4f} | Trades: {candle.trade_count}")
        print(f"   Processing Latency: {processing_latency:.1f}ms")
        
        # Show HFT features if available
        if hasattr(candle, 'hft_features') and candle.hft_features:
            features = candle.hft_features
            print(f"   üìä HFT FEATURES:")
            if 'sma_5' in features:
                print(f"      SMA(5): ${features['sma_5']:.2f}")
            if 'ema_5' in features:
                print(f"      EMA(5): ${features['ema_5']:.2f}")
            if 'rsi_5' in features:
                print(f"      RSI(5): {features['rsi_5']:.1f}")
            if 'price_volatility_5' in features:
                print(f"      Volatility(5): {features['price_volatility_5']:.4f}")
            if 'volume_ratio' in features:
                print(f"      Volume Ratio: {features['volume_ratio']:.2f}")
    
    async def _mock_bigquery_streaming(self, candle, hft_features):
        """Mock BigQuery streaming (shows what would be streamed)"""
        if candle.timeframe == '1m':  # Only show for 1m candles to avoid spam
            
            # This is what would be streamed to BigQuery
            bq_data = {
                'symbol': candle.symbol,
                'exchange': self.exchange,
                'timestamp': candle.timestamp_in,
                'timestamp_out': candle.timestamp_out,
                'timeframe': candle.timeframe,
                'data_type': 'candles',
                
                # OHLCV data
                'open': candle.open,
                'high': candle.high,
                'low': candle.low,
                'close': candle.close,
                'volume': candle.volume,
                'trade_count': candle.trade_count,
                'vwap': candle.vwap,
            }
            
            # Add HFT features
            if hft_features:
                for key, value in hft_features.items():
                    if key not in ['symbol', 'timeframe', 'timestamp']:
                        bq_data[key] = value
            
            print(f"   üíæ BIGQUERY STREAMING: candles_1m table")
            print(f"      Partitioned by: timestamp_out (HOUR)")
            print(f"      Clustered by: exchange, symbol")
            print(f"      TTL: 30 days (live data)")
    
    async def _show_final_stats(self, completed_candles):
        """Show final demo statistics"""
        runtime = datetime.now(timezone.utc) - self.stats['start_time']
        
        print("\n" + "=" * 60)
        print("üìä UNIFIED STREAMING DEMO - FINAL STATISTICS")
        print("=" * 60)
        
        print(f"Runtime: {runtime.total_seconds():.1f} seconds")
        print(f"Ticks processed: {self.stats['ticks_processed']:,}")
        print(f"Candles completed: {self.stats['candles_completed']}")
        print(f"HFT features computed: {self.stats['hft_features_computed']}")
        print(f"Processing rate: {self.stats['ticks_processed']/runtime.total_seconds():.1f} ticks/second")
        
        # Show candle breakdown by timeframe
        candle_counts = {}
        for candle in completed_candles:
            tf = candle.timeframe
            candle_counts[tf] = candle_counts.get(tf, 0) + 1
        
        print(f"\nCandles by timeframe:")
        for tf, count in candle_counts.items():
            print(f"  {tf}: {count} candles")
        
        # Show serve mode stats
        serve_stats = self.serve_mode.get_stats()
        print(f"\nServe mode stats:")
        print(f"  Candles served: {serve_stats['candles_served']}")
        print(f"  Features served: {serve_stats['features_served']}")
        
        # Show candle processor stats
        processor_stats = self.candle_processor.get_stats()
        print(f"\nCandle processor stats:")
        print(f"  Ticks per second: {processor_stats['ticks_per_second']:.1f}")
        print(f"  HFT features enabled: {processor_stats['hft_features_enabled']}")
        
        print("\n‚úÖ Demo completed - Unified streaming architecture working!")

async def main():
    """Run the unified streaming demo"""
    demo = UnifiedStreamingDemo()
    
    print("üöÄ UNIFIED STREAMING ARCHITECTURE DEMO")
    print("=" * 60)
    print("This demo shows:")
    print("  ‚úÖ Issue #003 SOLVED: All data types supported with fallbacks")
    print("  ‚úÖ Issue #004 SOLVED: Live CCXT instrument definitions")  
    print("  ‚úÖ Issue #009 SOLVED: Unified streaming architecture")
    print()
    print("Features demonstrated:")
    print("  ‚Ä¢ Unified HFT features (same code for historical + live)")
    print("  ‚Ä¢ Live candle processing with 15s and 1m timeframes")
    print("  ‚Ä¢ Real-time HFT feature computation")
    print("  ‚Ä¢ BigQuery streaming with optimized partitioning")
    print("  ‚Ä¢ Serve mode for downstream service integration")
    print("  ‚Ä¢ Proper timestamp handling (timestamp_out vs timestamp_in)")
    print()
    
    try:
        await demo.process_tick_stream()
    except KeyboardInterrupt:
        print("\nüõë Demo interrupted by user")
    except Exception as e:
        print(f"\n‚ùå Demo error: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())
